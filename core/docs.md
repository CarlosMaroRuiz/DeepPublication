# DeepSeekReseaoner - Documentaci√≥n

## Descripci√≥n

`DeepSeekReseaoner` es una clase Python que proporciona una interfaz simplificada para interactuar con el modelo `deepseek-reasoner` de DeepSeek. Esta clase maneja la comunicaci√≥n con la API, el historial de conversaciones, streaming de respuestas y manejo robusto de errores.

---

## üìö Conceptos Fundamentales

### üå°Ô∏è **Temperatura - Controlando la Creatividad**

La **temperatura** es un par√°metro que controla qu√© tan "creativo" o "aleatorio" ser√° el modelo en sus respuestas.

#### ¬øQu√© hace la temperatura?
- **Rango:** 0.0 a 2.0
- **Baja (0.0-0.5):** Respuestas m√°s predecibles, consistentes y "seguras"
- **Media (0.8-1.3):** Balance entre creatividad y coherencia
- **Alta (1.5-2.0):** Respuestas m√°s creativas, variadas e impredecibles

#### Ejemplos Pr√°cticos:

```python
# Temperatura BAJA (0.0) - Para matem√°ticas
result = reasoner.chat("¬øCu√°nto es 2+2?", temperature=0.0)
# Siempre responder√°: "4" (predecible y correcto)

# Temperatura ALTA (1.5) - Para creatividad  
result = reasoner.chat("Escribe un poema sobre gatos", temperature=1.5)
# Cada vez generar√° un poema completamente diferente
```

### üéØ **Tokens - Las Unidades de Texto**

Un **token** es la unidad b√°sica que el modelo entiende. No siempre equivale a una palabra.

#### ¬øQu√© cuenta como token?
- **Palabras comunes:** "casa" = 1 token
- **Palabras largas:** "extraordinario" = 2-3 tokens  
- **Puntuaci√≥n:** "," "." "?" = 1 token cada uno
- **N√∫meros:** "123" = 1 token, "12345" = 2-3 tokens
- **Espacios:** Tambi√©n cuentan como tokens

#### Regla pr√°ctica:
```
üìè 1 token ‚âà 4 caracteres en espa√±ol
üìè 100 tokens ‚âà 75-80 palabras
üìè 1000 tokens ‚âà 750 palabras (una p√°gina de texto)
```

#### Ejemplo de conteo:
```python
# Texto: "Hola, ¬øc√≥mo est√°s?"
# Tokens: ["Hola", ",", " ¬ø", "c√≥mo", " est", "√°s", "?"] = ~7 tokens

result = reasoner.chat("Pregunta corta", max_tokens=50)
# Limitar√° la respuesta a ~40 palabras
```

### üì° **Streaming - Respuestas en Tiempo Real**

El **streaming** permite ver la respuesta del modelo mientras se genera, palabra por palabra.

#### Diferencias Visuales:

**Sin Streaming (stream=False):**
```
Usuario: "Explica qu√© es Python"
[Esperando...] ‚è≥
[Esperando...] ‚è≥  
[Esperando...] ‚è≥
Respuesta completa: "Python es un lenguaje de programaci√≥n..."
```

**Con Streaming (stream=True):**
```
Usuario: "Explica qu√© es Python"  
Respuesta: "Python es un lenguaje de programaci√≥n..."
          ‚Üë Aparece palabra por palabra
```

#### Cu√°ndo usar cada uno:

| Situaci√≥n | Recomendaci√≥n | Raz√≥n |
|-----------|---------------|-------|
| Respuestas cortas (< 50 palabras) | `stream=False` | No hay ventaja notable |
| Explicaciones largas | `stream=True` | Mejor experiencia de usuario |
| C√≥digo/JSON/Datos estructurados | `stream=False` | Easier parsing |
| Conversaciones interactivas | `stream=True` | Sensaci√≥n de conversaci√≥n real |
| Procesamiento autom√°tico | `stream=False` | M√°s f√°cil de procesar |

---

## üìã Gu√≠a de Casos de Uso

### 1. üßÆ **Coding / Math** (Temperature: 0.0)

**Cu√°ndo usar:** Cuando necesitas respuestas exactas, precisas y consistentes.

**Caracter√≠sticas:**
- ‚úÖ Respuestas determin√≠sticas
- ‚úÖ C√°lculos exactos
- ‚úÖ C√≥digo funcional
- ‚ùå Poca variaci√≥n en respuestas

```python
# Ejemplo: Resolver problemas matem√°ticos
result = reasoner.chat(
    message="Resuelve la ecuaci√≥n: 3x + 7 = 22",
    temperature=0.0,
    max_tokens=200
)

# Ejemplo: Generar c√≥digo
result = reasoner.chat(
    message="Escribe una funci√≥n Python para ordenar una lista",
    temperature=0.0,
    stream=False  # Para c√≥digo es mejor sin streaming
)
```

**Por qu√© temperatura 0.0:**
- Los problemas matem√°ticos tienen UNA respuesta correcta
- El c√≥digo debe ser sint√°cticamente correcto
- Necesitas consistencia entre ejecuciones

### 2. üìä **Data Cleaning / Data Analysis** (Temperature: 1.0)

**Cu√°ndo usar:** Para an√°lisis de datos, limpieza y tareas que requieren metodolog√≠a pero con cierta flexibilidad.

**Caracter√≠sticas:**
- ‚úÖ Enfoque metodol√≥gico
- ‚úÖ Algo de creatividad en soluciones
- ‚úÖ Diferentes perspectivas de an√°lisis
- ‚öñÔ∏è Balance entre precisi√≥n y creatividad

```python
# Ejemplo: An√°lisis de datos
result = reasoner.chat(
    message="""
    Tengo estos datos de ventas [1200, 1400, 1100, 1600, 1300].
    ¬øQu√© insights puedes obtener y qu√© visualizaci√≥n recomendar√≠as?
    """,
    temperature=1.0,
    stream=True  # Para ver el proceso de an√°lisis
)

# Ejemplo: Limpieza de datos
result = reasoner.chat(
    message="¬øC√≥mo limpio datos con valores nulos en pandas?",
    temperature=1.0,
    system_prompt="Eres un experto en ciencia de datos"
)
```

**Por qu√© temperatura 1.0:**
- Permite diferentes enfoques metodol√≥gicos
- Da flexibilidad para soluciones creativas
- Mantiene rigor cient√≠fico

### 3. üí¨ **General Conversation** (Temperature: 1.3)

**Cu√°ndo usar:** Conversaciones casuales, explicaciones generales, consultas cotidianas.

**Caracter√≠sticas:**
- ‚úÖ Respuestas naturales y variadas
- ‚úÖ Tono conversacional
- ‚úÖ Explicaciones adaptables
- ‚úÖ Personalidad m√°s evidente

```python
# Ejemplo: Conversaci√≥n casual
result = reasoner.chat(
    message="¬øQu√© opinas sobre trabajar desde casa?",
    temperature=1.3,
    stream=True,  # Para conversaci√≥n natural
    maintain_history=True  # Para mantener contexto
)

# Ejemplo: Explicaciones generales
result = reasoner.chat(
    message="Expl√≠came qu√© es la inteligencia artificial como si tuviera 12 a√±os",
    temperature=1.3,
    system_prompt="Eres un profesor paciente y did√°ctico"
)
```

**Por qu√© temperatura 1.3:**
- Las conversaciones humanas son naturalmente variadas
- Permite respuestas m√°s "humanas" y menos rob√≥ticas
- Da espacio para personalidad y matices

### 4. üåç **Translation** (Temperature: 1.3)

**Cu√°ndo usar:** Traducci√≥n de textos, localizaci√≥n, adaptaci√≥n cultural.

**Caracter√≠sticas:**
- ‚úÖ Traducciones naturales
- ‚úÖ Adaptaci√≥n cultural
- ‚úÖ Diferentes estilos seg√∫n contexto
- ‚úÖ Manejo de expresiones idiom√°ticas

```python
# Ejemplo: Traducci√≥n b√°sica
result = reasoner.chat(
    message="Traduce al ingl√©s: 'Me da mucha lata hacer la tarea'",
    temperature=1.3,
    system_prompt="Traduce considerando el contexto cultural mexicano"
)

# Ejemplo: Traducci√≥n con contexto
result = reasoner.chat(
    message="""
    Traduce este email comercial al ingl√©s, manteniendo un tono profesional:
    "Estimado cliente, esperamos que est√© bien..."
    """,
    temperature=1.3,
    max_tokens=500
)
```

**Por qu√© temperatura 1.3:**
- Las traducciones pueden tener m√∫ltiples variantes correctas
- Permite adaptaci√≥n cultural y de registro
- Da flexibilidad para expresiones idiom√°ticas

### 5. üé® **Creative Writing / Poetry** (Temperature: 1.5)

**Cu√°ndo usar:** Escritura creativa, poemas, historias, contenido art√≠stico.

**Caracter√≠sticas:**
- ‚úÖ M√°xima creatividad
- ‚úÖ Respuestas √∫nicas e impredecibles
- ‚úÖ Estilo literario variado
- ‚ö†Ô∏è Puede ser inconsistente

```python
# Ejemplo: Escribir poes√≠a
result = reasoner.chat(
    message="Escribe un poema sobre la soledad en la ciudad",
    temperature=1.5,
    stream=True,  # Para ver la creatividad surgir
    max_tokens=300
)

# Ejemplo: Crear una historia
result = reasoner.chat(
    message="""
    Escribe el inicio de una historia de ciencia ficci√≥n donde 
    los humanos descubren que las plantas pueden comunicarse
    """,
    temperature=1.5,
    system_prompt="Eres un escritor de ciencia ficci√≥n imaginativo"
)
```

**Por qu√© temperatura 1.5:**
- La creatividad requiere aleatoriedad e impredecibilidad
- Cada ejecuci√≥n debe generar contenido √∫nico
- Permite explorar ideas no convencionales

---

## üéØ Matriz de Decisi√≥n R√°pida

| Necesito... | Temperature | Streaming | Max Tokens | Ejemplo |
|-------------|-------------|-----------|------------|---------|
| **C√≥digo exacto** | 0.0 | ‚ùå No | 500-1000 | `reasoner.chat("funci√≥n fibonacci", temperature=0.0)` |
| **C√°lculo matem√°tico** | 0.0 | ‚ùå No | 200-500 | `reasoner.chat("derivada de x¬≤", temperature=0.0)` |
| **An√°lisis de datos** | 1.0 | ‚úÖ S√≠ | 800-1500 | `reasoner.chat("analiza estos datos", temperature=1.0, stream=True)` |
| **Explicaci√≥n t√©cnica** | 1.0 | ‚úÖ S√≠ | 1000-2000 | `reasoner.chat("explica blockchain", temperature=1.0, stream=True)` |
| **Charla casual** | 1.3 | ‚úÖ S√≠ | 500-1000 | `reasoner.chat("¬øqu√© tal tu d√≠a?", temperature=1.3, stream=True)` |
| **Traducir texto** | 1.3 | ‚ùå No | 300-800 | `reasoner.chat("traduce: hello", temperature=1.3)` |
| **Escribir historia** | 1.5 | ‚úÖ S√≠ | 1500-3000 | `reasoner.chat("escribe cuento", temperature=1.5, stream=True)` |
| **Poema creativo** | 1.5 | ‚úÖ S√≠ | 200-500 | `reasoner.chat("poema sobre amor", temperature=1.5, stream=True)` |

## Instalaci√≥n

### Dependencias Requeridas

```bash
pip install openai tabulate
```

### Estructura de Archivos

```
proyecto/
‚îú‚îÄ‚îÄ config.py              # Configuraci√≥n con API key
‚îú‚îÄ‚îÄ deepseek_reasoner.py    # Clase principal
‚îî‚îÄ‚îÄ main.py                 # Archivo de uso
```

### Configuraci√≥n

Crea un archivo `config.py` con tu API key:

```python
# config.py
class Config:
    api_key = "tu_api_key_de_deepseek"

config = Config()
```

## Clase DeepSeekReseaoner

### Constructor

```python
DeepSeekReseaoner()
```

**Inicializa la clase con:**
- Cliente OpenAI configurado para DeepSeek API
- Modelo `deepseek-reasoner`
- Historial de conversaci√≥n vac√≠o

---

## M√©todos Principales

### 1. `get_information_temperature()` (M√©todo Est√°tico)

Muestra una tabla con temperaturas recomendadas para diferentes casos de uso.

```python
DeepSeekReseaoner.get_information_temperature()
```

**Salida:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ UseCase                         ‚îÇ Temperature ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Coding / Math                   ‚îÇ         0.0 ‚îÇ
‚îÇ Data Cleaning / Data Analysis   ‚îÇ         1.0 ‚îÇ
‚îÇ General Conversation            ‚îÇ         1.3 ‚îÇ
‚îÇ Translation                     ‚îÇ         1.3 ‚îÇ
‚îÇ Creative Writing / Poetry       ‚îÇ         1.5 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2. `chat()` - M√©todo Principal

Env√≠a mensajes al modelo y maneja las respuestas.

```python
chat(
    message: str, 
    temperature: float = 1.0,
    max_tokens: Optional[int] = None,
    system_prompt: Optional[str] = None,
    stream: bool = False,
    maintain_history: bool = True
) -> Dict[str, Any]
```

#### Par√°metros

| Par√°metro | Tipo | Default | Descripci√≥n |
|-----------|------|---------|-------------|
| `message` | `str` | - | **Requerido.** El mensaje del usuario |
| `temperature` | `float` | `1.0` | Controla aleatoriedad (0.0-2.0) |
| `max_tokens` | `int` | `None` | M√°ximo tokens de salida |
| `system_prompt` | `str` | `None` | Prompt del sistema |
| `stream` | `bool` | `False` | Habilita streaming |
| `maintain_history` | `bool` | `True` | Mantiene historial |

#### Valor de Retorno

**En caso exitoso:**
```python
{
    "success": True,
    "response": "Respuesta del modelo",
    "usage": {
        "input_tokens": 100,
        "output_tokens": 150,
        "total_tokens": 250
    },
    "model": "deepseek-reasoner",
    "reasoning_content": "Contenido de razonamiento",  # Solo si disponible
    "streamed": True  # Solo en modo streaming
}
```

**En caso de error:**
```python
{
    "success": False,
    "error": "Descripci√≥n del error",
    "error_type": "Tipo de error",
    "solution": "Soluci√≥n sugerida",
    "status_code": 400,  # Si disponible
    "user_message": "Mensaje original"
}
```

---

## M√©todos de Historial

### 3. `clear_history()`

Limpia el historial de conversaci√≥n.

```python
reasoner.clear_history()
# Output: "Historial de conversaci√≥n limpiado."
```

### 4. `get_history()`

Obtiene una copia del historial actual.

```python
history = reasoner.get_history()
# Returns: List[Dict[str, str]]
```

### 5. `save_conversation(filename: str)`

Guarda el historial en un archivo JSON.

```python
reasoner.save_conversation("mi_conversacion.json")
# Output: "Conversaci√≥n guardada en mi_conversacion.json"
```

### 6. `load_conversation(filename: str)`

Carga un historial desde archivo JSON.

```python
reasoner.load_conversation("mi_conversacion.json")
# Output: "Conversaci√≥n cargada desde mi_conversacion.json"
```

---

## Manejo de Errores

La clase maneja autom√°ticamente los siguientes errores de la API DeepSeek:

| C√≥digo | Tipo de Error | Soluci√≥n |
|--------|---------------|----------|
| 400 | Invalid Format | Verifica el formato de tu solicitud |
| 401 | Authentication Fails | Verifica tu API key |
| 402 | Insufficient Balance | Recarga tu cuenta |
| 422 | Invalid Parameters | Revisa los par√°metros de tu solicitud |
| 429 | Rate Limit Reached | Reduce la frecuencia de solicitudes |
| 500 | Server Error | Reintenta despu√©s de un momento |
| 503 | Server Overloaded | El servidor est√° sobrecargado |

---

## Ejemplos de Uso

### Uso B√°sico

```python
from deepseek_reasoner import DeepSeekReseaoner

# Crear instancia
reasoner = DeepSeekReseaoner()

# Mostrar temperaturas recomendadas
DeepSeekReseaoner.get_information_temperature()

# Chat b√°sico
result = reasoner.chat("¬øQu√© es Python?")
if result["success"]:
    print(result["response"])
else:
    print(f"Error: {result['error']}")
```

### Uso con Par√°metros Espec√≠ficos

```python
# Para matem√°ticas (temperatura baja)
result = reasoner.chat(
    message="Resuelve: 2x + 5 = 15",
    temperature=0.0,
    max_tokens=500
)

# Para creatividad (temperatura alta)
result = reasoner.chat(
    message="Escribe un poema sobre el mar",
    temperature=1.5,
    system_prompt="Eres un poeta rom√°ntico del siglo XIX"
)
```

### Streaming en Tiempo Real

```python
# Ver respuesta gener√°ndose palabra por palabra
result = reasoner.chat(
    message="Explica c√≥mo funciona una red neuronal",
    stream=True,
    temperature=1.0
)

# El texto aparece en tiempo real
# Al final tienes la respuesta completa en result["response"]
```

### Conversaci√≥n Continua

```python
# Primera pregunta
result1 = reasoner.chat("Hola, ¬øpuedes ayudarme con Python?")

# Segunda pregunta (mantiene contexto)
result2 = reasoner.chat("Espec√≠ficamente con listas")

# Ver historial
history = reasoner.get_history()
print(f"Mensajes en historial: {len(history)}")

# Guardar conversaci√≥n
reasoner.save_conversation("sesion_python.json")
```

### Manejo de Errores

```python
result = reasoner.chat("Pregunta muy compleja", max_tokens=100000)

if not result["success"]:
    print(f"Tipo de error: {result.get('error_type', 'Unknown')}")
    print(f"Mensaje: {result['error']}")
    if 'solution' in result:
        print(f"Soluci√≥n: {result['solution']}")
```

### Caso de Uso Completo

```python
def chatbot_session():
    reasoner = DeepSeekReseaoner()
    
    print("ü§ñ Chatbot DeepSeek iniciado (escribe 'salir' para terminar)")
    
    while True:
        user_input = input("\nüí¨ T√∫: ")
        
        if user_input.lower() in ['salir', 'exit', 'quit']:
            break
            
        # Determinar temperatura seg√∫n el tipo de pregunta
        if any(word in user_input.lower() for word in ['matem√°tica', 'c√≥digo', 'programar']):
            temp = 0.0
        elif any(word in user_input.lower() for word in ['historia', 'poema', 'creativo']):
            temp = 1.5
        else:
            temp = 1.3
            
        result = reasoner.chat(
            message=user_input,
            temperature=temp,
            stream=True  # Respuesta en tiempo real
        )
        
        if not result["success"]:
            print(f"‚ùå Error: {result['error']}")
    
    # Guardar sesi√≥n al finalizar
    reasoner.save_conversation(f"sesion_{int(time.time())}.json")
    print("üëã Sesi√≥n guardada. ¬°Hasta luego!")

if __name__ == "__main__":
    chatbot_session()
```

---

## Notas Importantes

### Costos y Tokens

- El modelo `deepseek-reasoner` incluye tokens de razonamiento (CoT) en el conteo
- Revisa los precios en la documentaci√≥n oficial de DeepSeek
- Usa `max_tokens` para controlar costos

### L√≠mites

- Contexto m√°ximo: 64K tokens
- Output m√°ximo por defecto: 32K tokens
- Sin l√≠mites estrictos de rate limit

### Mejores Pr√°cticas

1. **Usa temperaturas apropiadas** seg√∫n el caso de uso
2. **Habilita streaming** para respuestas largas
3. **Maneja errores** siempre verificando `result["success"]`
4. **Guarda conversaciones importantes** con `save_conversation()`
5. **Limpia historial** cuando cambies de tema con `clear_history()`

---

## Licencia

Esta clase es de uso libre. Aseg√∫rate de cumplir con los t√©rminos de servicio de DeepSeek API.